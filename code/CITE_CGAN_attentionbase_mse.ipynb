{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4df3fa-853c-4301-9ec9-0fb81ed4847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from module import *\n",
    "from earlystopping import *modu\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2432328c-f9a9-42eb-ba9d-47e8994f33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "feature_path = '../dataset/'\n",
    "train_cite_X = np.load(feature_path+'train_cite_X.npy')\n",
    "test_cite_X = np.load(feature_path+'test_cite_X.npy')\n",
    "train_cite_y = np.load(feature_path+'train_cite_targets.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5067096e-644e-4933-af51-8c7d93eac38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = train_cite_X  \n",
    "B = train_cite_y  \n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "B_tensor = torch.tensor(B, dtype=torch.float32)\n",
    "dataset = TensorDataset(A_tensor, B_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6de1435-9d50-4df8-9af4-fdeb738443f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70988, 1009), (70988, 140))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cite_X.shape, train_cite_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375a4d0d-e678-4432-b403-af0deccb3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ffb6897-2692-4175-8dba-9b8320b333f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dm/anaconda3/envs/attention/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], d_loss: 0.1902, g_loss: 11.5589, val_loss: 10.7048\n",
      "Epoch [2/50], d_loss: 0.1150, g_loss: 8.4411, val_loss: 7.4997\n",
      "Epoch [3/50], d_loss: 0.0505, g_loss: 6.3626, val_loss: 5.4850\n",
      "Epoch [4/50], d_loss: 0.0154, g_loss: 5.9516, val_loss: 4.9735\n",
      "Epoch [5/50], d_loss: 0.0056, g_loss: 5.6897, val_loss: 4.7968\n",
      "Epoch [6/50], d_loss: 0.0022, g_loss: 5.4459, val_loss: 4.4443\n",
      "Epoch [7/50], d_loss: 0.0020, g_loss: 5.0378, val_loss: 4.0786\n",
      "Epoch [8/50], d_loss: 0.0042, g_loss: 4.7848, val_loss: 3.9401\n",
      "Epoch [9/50], d_loss: 0.0146, g_loss: 4.8377, val_loss: 4.0395\n",
      "Epoch [10/50], d_loss: 0.0255, g_loss: 5.0580, val_loss: 4.0211\n",
      "Epoch [11/50], d_loss: 0.0015, g_loss: 4.8313, val_loss: 3.8224\n",
      "Epoch [12/50], d_loss: 0.0021, g_loss: 4.7325, val_loss: 3.7033\n",
      "Epoch [13/50], d_loss: 0.0004, g_loss: 4.5692, val_loss: 3.6301\n",
      "Epoch [14/50], d_loss: 0.0006, g_loss: 4.5084, val_loss: 3.5705\n",
      "Epoch [15/50], d_loss: 0.0003, g_loss: 4.5760, val_loss: 3.5379\n",
      "Epoch [16/50], d_loss: 0.0004, g_loss: 4.4441, val_loss: 3.4574\n",
      "Epoch [17/50], d_loss: 0.0004, g_loss: 4.4259, val_loss: 3.4288\n",
      "Epoch [18/50], d_loss: 0.0004, g_loss: 4.3066, val_loss: 3.3418\n",
      "Epoch [19/50], d_loss: 0.0003, g_loss: 4.2557, val_loss: 3.3377\n",
      "Epoch [20/50], d_loss: 0.0005, g_loss: 4.2325, val_loss: 3.2856\n",
      "Epoch [21/50], d_loss: 0.0004, g_loss: 4.2275, val_loss: 3.2635\n",
      "Epoch [22/50], d_loss: 0.0005, g_loss: 4.1329, val_loss: 3.2446\n",
      "Epoch [23/50], d_loss: 0.0141, g_loss: 4.0387, val_loss: 3.2840\n",
      "Epoch [24/50], d_loss: 0.4169, g_loss: 4.0156, val_loss: 3.7406\n",
      "Epoch [25/50], d_loss: 0.4416, g_loss: 4.2577, val_loss: 3.8712\n",
      "Epoch [26/50], d_loss: 0.3763, g_loss: 4.4159, val_loss: 3.7248\n",
      "Epoch [27/50], d_loss: 0.2413, g_loss: 4.0354, val_loss: 3.6259\n",
      "Early stopping\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.2070, g_loss: 11.5439, val_loss: 10.8259\n",
      "Epoch [2/50], d_loss: 0.0985, g_loss: 8.7522, val_loss: 7.8617\n",
      "Epoch [3/50], d_loss: 0.0403, g_loss: 6.7543, val_loss: 5.7788\n",
      "Epoch [4/50], d_loss: 0.0087, g_loss: 5.9600, val_loss: 4.9884\n",
      "Epoch [5/50], d_loss: 0.0044, g_loss: 5.5251, val_loss: 4.6051\n",
      "Epoch [6/50], d_loss: 0.0029, g_loss: 5.3465, val_loss: 4.3517\n",
      "Epoch [7/50], d_loss: 0.0018, g_loss: 5.2135, val_loss: 4.2042\n",
      "Epoch [8/50], d_loss: 0.0021, g_loss: 4.9549, val_loss: 4.0481\n",
      "Epoch [9/50], d_loss: 0.0060, g_loss: 4.7828, val_loss: 3.9583\n",
      "Epoch [10/50], d_loss: 0.3904, g_loss: 4.2586, val_loss: 4.2088\n",
      "Epoch [11/50], d_loss: 0.6152, g_loss: 4.7305, val_loss: 4.4590\n",
      "Epoch [12/50], d_loss: 0.1886, g_loss: 4.8339, val_loss: 4.5312\n",
      "Epoch [13/50], d_loss: 0.1038, g_loss: 4.6722, val_loss: 4.0561\n",
      "Epoch [14/50], d_loss: 0.0828, g_loss: 4.8419, val_loss: 4.0381\n",
      "Early stopping\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.1667, g_loss: 11.8698, val_loss: 11.1046\n",
      "Epoch [2/50], d_loss: 0.1017, g_loss: 8.9756, val_loss: 8.0901\n",
      "Epoch [3/50], d_loss: 0.0481, g_loss: 6.7383, val_loss: 5.9260\n",
      "Epoch [4/50], d_loss: 0.0135, g_loss: 5.9666, val_loss: 5.1777\n",
      "Epoch [5/50], d_loss: 0.0051, g_loss: 5.7644, val_loss: 4.9402\n",
      "Epoch [6/50], d_loss: 0.0032, g_loss: 5.7695, val_loss: 4.7888\n",
      "Epoch [7/50], d_loss: 0.0016, g_loss: 5.6254, val_loss: 4.5807\n",
      "Epoch [8/50], d_loss: 0.0014, g_loss: 5.3677, val_loss: 4.3874\n",
      "Epoch [9/50], d_loss: 0.0008, g_loss: 5.0445, val_loss: 4.2374\n",
      "Epoch [10/50], d_loss: 0.0009, g_loss: 5.0006, val_loss: 3.8933\n",
      "Epoch [11/50], d_loss: 0.0008, g_loss: 4.7126, val_loss: 3.7054\n",
      "Epoch [12/50], d_loss: 0.0007, g_loss: 4.5313, val_loss: 3.6003\n",
      "Epoch [13/50], d_loss: 0.0004, g_loss: 4.5072, val_loss: 3.5500\n",
      "Epoch [14/50], d_loss: 0.0008, g_loss: 4.4520, val_loss: 3.5043\n",
      "Epoch [15/50], d_loss: 0.0006, g_loss: 4.3836, val_loss: 3.5128\n",
      "Epoch [16/50], d_loss: 0.0005, g_loss: 4.4142, val_loss: 3.4487\n",
      "Epoch [17/50], d_loss: 0.0005, g_loss: 4.3950, val_loss: 3.4356\n",
      "Epoch [18/50], d_loss: 0.0023, g_loss: 4.3777, val_loss: 3.4236\n",
      "Epoch [19/50], d_loss: 0.2836, g_loss: 4.1181, val_loss: 4.0130\n",
      "Epoch [20/50], d_loss: 0.2082, g_loss: 4.7754, val_loss: 4.3243\n",
      "Epoch [21/50], d_loss: 0.0475, g_loss: 4.8835, val_loss: 4.0367\n",
      "Epoch [22/50], d_loss: 0.0625, g_loss: 4.3783, val_loss: 3.7451\n",
      "Epoch [23/50], d_loss: 0.0834, g_loss: 4.2178, val_loss: 3.7046\n",
      "Early stopping\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.2224, g_loss: 11.5156, val_loss: 10.7907\n",
      "Epoch [2/50], d_loss: 0.1014, g_loss: 8.5803, val_loss: 7.6982\n",
      "Epoch [3/50], d_loss: 0.0277, g_loss: 6.4464, val_loss: 5.6715\n",
      "Epoch [4/50], d_loss: 0.0108, g_loss: 5.9006, val_loss: 5.0892\n",
      "Epoch [5/50], d_loss: 0.0113, g_loss: 5.7812, val_loss: 4.9847\n",
      "Epoch [6/50], d_loss: 0.0042, g_loss: 5.6145, val_loss: 4.6749\n",
      "Epoch [7/50], d_loss: 0.0019, g_loss: 5.3186, val_loss: 4.4504\n",
      "Epoch [8/50], d_loss: 0.0012, g_loss: 5.2820, val_loss: 4.3309\n",
      "Epoch [9/50], d_loss: 0.0019, g_loss: 5.1413, val_loss: 4.2555\n",
      "Epoch [10/50], d_loss: 0.0009, g_loss: 5.0034, val_loss: 4.1208\n",
      "Epoch [11/50], d_loss: 0.0008, g_loss: 4.8697, val_loss: 3.9009\n",
      "Epoch [12/50], d_loss: 0.0013, g_loss: 4.6494, val_loss: 3.6929\n",
      "Epoch [13/50], d_loss: 0.0017, g_loss: 4.5312, val_loss: 3.6403\n",
      "Epoch [14/50], d_loss: 0.0227, g_loss: 4.3629, val_loss: 3.8543\n",
      "Epoch [15/50], d_loss: 0.4430, g_loss: 4.3402, val_loss: 4.1670\n",
      "Epoch [16/50], d_loss: 0.3746, g_loss: 4.0595, val_loss: 3.9187\n",
      "Epoch [17/50], d_loss: 0.2399, g_loss: 4.0718, val_loss: 3.7941\n",
      "Epoch [18/50], d_loss: 0.1566, g_loss: 4.1399, val_loss: 3.6710\n",
      "Early stopping\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.2178, g_loss: 11.9042, val_loss: 11.0991\n",
      "Epoch [2/50], d_loss: 0.1442, g_loss: 8.9498, val_loss: 8.0988\n",
      "Epoch [3/50], d_loss: 0.0470, g_loss: 6.7101, val_loss: 5.8823\n",
      "Epoch [4/50], d_loss: 0.0168, g_loss: 5.9691, val_loss: 5.0787\n",
      "Epoch [5/50], d_loss: 0.0039, g_loss: 5.4774, val_loss: 4.6489\n",
      "Epoch [6/50], d_loss: 0.0025, g_loss: 5.3659, val_loss: 4.4845\n",
      "Epoch [7/50], d_loss: 0.0018, g_loss: 5.2056, val_loss: 4.3564\n",
      "Epoch [8/50], d_loss: 0.0017, g_loss: 5.0730, val_loss: 4.3111\n",
      "Epoch [9/50], d_loss: 0.0010, g_loss: 5.0593, val_loss: 4.2354\n",
      "Epoch [10/50], d_loss: 0.0010, g_loss: 5.0915, val_loss: 4.1576\n",
      "Epoch [11/50], d_loss: 0.0009, g_loss: 5.0589, val_loss: 4.1410\n",
      "Epoch [12/50], d_loss: 0.0006, g_loss: 5.0256, val_loss: 4.0634\n",
      "Epoch [13/50], d_loss: 0.0005, g_loss: 4.8431, val_loss: 3.9657\n",
      "Epoch [14/50], d_loss: 0.0005, g_loss: 4.7105, val_loss: 3.7582\n",
      "Epoch [15/50], d_loss: 0.0004, g_loss: 4.6101, val_loss: 3.6336\n",
      "Epoch [16/50], d_loss: 0.0005, g_loss: 4.5686, val_loss: 3.5839\n",
      "Epoch [17/50], d_loss: 0.0004, g_loss: 4.3707, val_loss: 3.5038\n",
      "Epoch [18/50], d_loss: 0.0003, g_loss: 4.4120, val_loss: 3.5480\n",
      "Epoch [19/50], d_loss: 0.0003, g_loss: 4.4233, val_loss: 3.4620\n",
      "Epoch [20/50], d_loss: 0.0004, g_loss: 4.4624, val_loss: 3.4234\n",
      "Epoch [21/50], d_loss: 0.0005, g_loss: 4.4067, val_loss: 3.3703\n",
      "Epoch [22/50], d_loss: 0.0002, g_loss: 4.3969, val_loss: 3.3866\n",
      "Epoch [23/50], d_loss: 0.0007, g_loss: 4.3016, val_loss: 3.3113\n",
      "Epoch [24/50], d_loss: 0.0006, g_loss: 4.3029, val_loss: 3.3565\n",
      "Epoch [25/50], d_loss: 0.0008, g_loss: 4.2131, val_loss: 3.3766\n",
      "Epoch [26/50], d_loss: 0.0371, g_loss: 4.0547, val_loss: 3.3873\n",
      "Epoch [27/50], d_loss: 0.0049, g_loss: 4.5759, val_loss: 3.5424\n",
      "Epoch [28/50], d_loss: 0.0022, g_loss: 4.3990, val_loss: 3.4119\n",
      "Early stopping\n",
      "CPU times: user 2min 58s, sys: 1min 6s, total: 4min 5s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    trainloader = DataLoader(dataset, batch_size=8192, sampler=train_subsampler,num_workers=8)\n",
    "    testloader = DataLoader(dataset, batch_size=8192, sampler=test_subsampler,num_workers=8)\n",
    "\n",
    "    generator, discriminator = create_models()\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        for data in trainloader:\n",
    "            A_batch, B_batch = data\n",
    "            A_batch, B_batch = A_batch.to(device), B_batch.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            real_output = discriminator(B_batch)\n",
    "            fake_B = generator(A_batch)\n",
    "            fake_output = discriminator(fake_B.detach())\n",
    "            d_loss_real = criterion(real_output, torch.ones_like(real_output))\n",
    "            d_loss_fake = criterion(fake_output, torch.zeros_like(fake_output))\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_output = discriminator(fake_B)\n",
    "            g_loss = criterion(fake_output, torch.ones_like(fake_output)) + criterion(fake_B, B_batch)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "        # Validate\n",
    "        generator.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                A_batch, B_batch = data\n",
    "                A_batch, B_batch = A_batch.to(device), B_batch.to(device)\n",
    "                fake_B = generator(A_batch)\n",
    "                val_loss += criterion(fake_B, B_batch).item()\n",
    "        \n",
    "        val_loss /= len(testloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, val_loss: {val_loss:.4f}')\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9c3de2-9c18-4ed6-b483-e9b2fb1c1cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5994527 ,  0.51441234,  0.97809494, ...,  0.93337363,\n",
       "         4.049357  ,  4.8270545 ],\n",
       "       [ 0.5995103 ,  0.51434344,  0.97802305, ...,  0.9333096 ,\n",
       "         4.0486646 ,  4.8266973 ],\n",
       "       [ 0.5865684 ,  0.520134  ,  0.9948261 , ...,  0.943077  ,\n",
       "         4.16027   ,  4.852188  ],\n",
       "       ...,\n",
       "       [ 0.8174296 ,  0.40102977,  1.154908  , ...,  1.200386  ,\n",
       "         6.4875264 ,  5.346298  ],\n",
       "       [-0.09853111,  0.12912661,  1.0921547 , ...,  0.70547223,\n",
       "         4.8214574 ,  3.651095  ],\n",
       "       [ 0.03799064,  0.32101083,  1.3517659 , ...,  0.82057786,\n",
       "         6.433246  ,  4.56198   ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_B_from_A(new_A):\n",
    "    new_A_tensor = torch.tensor(new_A, dtype=torch.float32)\n",
    "    dataset = TensorDataset(new_A_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "    generator.eval()\n",
    "    generated_B = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            A_batch = data[0].to(device)\n",
    "            fake_B = generator(A_batch)\n",
    "            generated_B.append(fake_B.cpu().numpy())\n",
    "    \n",
    "    generated_B = np.concatenate(generated_B, axis=0)\n",
    "    return generated_B\n",
    "\n",
    "generated_B = generate_B_from_A(test_cite_X)\n",
    "generated_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f121ac-4020-49e6-98e8-2157c130b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48663, 140)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf1a1d-0905-4dfd-9e34-177311424dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Data collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d71d55-2373-4775-96a6-f2d5e4ea8265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2150f55becb</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.599453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b7edf8a4da</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.599510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1b26cb1057b</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.586568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>917168fa6f83</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.593099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b29feeca86d</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.589955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812815</th>\n",
       "      <td>a9b4d99f1f50</td>\n",
       "      <td>CD224</td>\n",
       "      <td>2.738467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812816</th>\n",
       "      <td>0e2c1d0782af</td>\n",
       "      <td>CD224</td>\n",
       "      <td>2.715506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812817</th>\n",
       "      <td>a3cbc5aa0ec3</td>\n",
       "      <td>CD224</td>\n",
       "      <td>5.346298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812818</th>\n",
       "      <td>75b350243add</td>\n",
       "      <td>CD224</td>\n",
       "      <td>3.651095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812819</th>\n",
       "      <td>ad5a949989b2</td>\n",
       "      <td>CD224</td>\n",
       "      <td>4.561980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812820 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cell_id gene_id    target\n",
       "0        c2150f55becb    CD86  0.599453\n",
       "1        65b7edf8a4da    CD86  0.599510\n",
       "2        c1b26cb1057b    CD86  0.586568\n",
       "3        917168fa6f83    CD86  0.593099\n",
       "4        2b29feeca86d    CD86  0.589955\n",
       "...               ...     ...       ...\n",
       "6812815  a9b4d99f1f50   CD224  2.738467\n",
       "6812816  0e2c1d0782af   CD224  2.715506\n",
       "6812817  a3cbc5aa0ec3   CD224  5.346298\n",
       "6812818  75b350243add   CD224  3.651095\n",
       "6812819  ad5a949989b2   CD224  4.561980\n",
       "\n",
       "[6812820 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = '../dataset/'\n",
    "metadata = pd.read_csv(input_path+'metadata.csv')[['cell_id','technology']]\n",
    "evaluation_ids = pd.read_csv(input_path+'evaluation_ids.csv')\n",
    "evaluation_ids = evaluation_ids.merge(metadata, on=['cell_id'], how='left')\n",
    "\n",
    "# cite\n",
    "train_cite_targets = pd.read_hdf(input_path+'train_cite_targets.h5')\n",
    "cite_targets = train_cite_targets.columns.values.tolist()\n",
    "del train_cite_targets\n",
    "gc.collect()\n",
    "test_preds_cite = pd.DataFrame(generated_B, columns=cite_targets)\n",
    "\n",
    "test_cite_inputs_id = pd.read_feather(feature_path+'test_cite_inputs_id.feather')\n",
    "test_preds_cite['cell_id'] = test_cite_inputs_id['cell_id']\n",
    "test_preds_cite = test_preds_cite[test_preds_cite['cell_id'].isin(evaluation_ids['cell_id'])]\n",
    "test_preds_cite = pd.melt(test_preds_cite,id_vars='cell_id')\n",
    "test_preds_cite.columns = ['cell_id','gene_id','target']\n",
    "del test_cite_inputs_id\n",
    "gc.collect()\n",
    "\n",
    "test_preds_cite.to_csv('../dataset/pred_cite.csv')\n",
    "test_preds_cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53002a81-0987-4bc7-bb34-6b304a98bc58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
