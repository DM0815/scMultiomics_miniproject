{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4df3fa-853c-4301-9ec9-0fb81ed4847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from earlystopping import *\n",
    "from module_multiome import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0294ea0-712e-43b8-a395-a0ae163f295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105942, 500), (105942, 23418))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "feature_path = '../dataset/'\n",
    "\n",
    "train_df = pd.read_feather(feature_path+'train_multi_inputs_id.feather')\n",
    "test_df = pd.read_feather(feature_path+'train_multi_inputs_id.feather')\n",
    "\n",
    "train_multi_X = np.load(feature_path+'train_multi_X.npy')\n",
    "test_multi_X = np.load(feature_path+'test_multi_X.npy')\n",
    "train_multi_y = np.load(feature_path+'train_multi_targets.npy') \n",
    "A = train_multi_X  \n",
    "B = train_multi_y  \n",
    "A_tensor = torch.tensor(A, dtype=torch.float32)\n",
    "B_tensor = torch.tensor(B, dtype=torch.float32)\n",
    "dataset = TensorDataset(A_tensor, B_tensor)\n",
    "train_multi_X.shape, train_multi_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbbe895-3922-4761-8c3f-2f8c8ef4252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0d191b-5bbb-4c50-b3b3-3ae34775ff62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dm/anaconda3/envs/attention/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], d_loss: 0.0000, g_loss: 4.8600, val_loss: 3.7620\n",
      "Epoch [2/50], d_loss: 0.0000, g_loss: 3.8105, val_loss: 2.7394\n",
      "Epoch [3/50], d_loss: 0.5003, g_loss: 2.3553, val_loss: 2.3485\n",
      "Epoch [4/50], d_loss: 0.5000, g_loss: 2.2238, val_loss: 2.2151\n",
      "Epoch [5/50], d_loss: 0.5000, g_loss: 2.1702, val_loss: 2.1691\n",
      "Epoch [6/50], d_loss: 0.5000, g_loss: 2.1554, val_loss: 2.1543\n",
      "Epoch [7/50], d_loss: 0.5000, g_loss: 2.1515, val_loss: 2.1491\n",
      "Epoch [8/50], d_loss: 0.5000, g_loss: 2.1430, val_loss: 2.1410\n",
      "Epoch [9/50], d_loss: 0.5000, g_loss: 2.1234, val_loss: 2.1166\n",
      "Epoch [10/50], d_loss: 0.5000, g_loss: 2.1115, val_loss: 2.1089\n",
      "Epoch [11/50], d_loss: 0.5000, g_loss: 2.1032, val_loss: 2.1062\n",
      "Epoch [12/50], d_loss: 0.5000, g_loss: 2.0995, val_loss: 2.0996\n",
      "Epoch [13/50], d_loss: 0.5000, g_loss: 2.1016, val_loss: 2.0963\n",
      "Epoch [14/50], d_loss: 0.5000, g_loss: 2.0882, val_loss: 2.0930\n",
      "Epoch [15/50], d_loss: 0.5000, g_loss: 2.0935, val_loss: 2.0917\n",
      "Epoch [16/50], d_loss: 0.5000, g_loss: 2.0887, val_loss: 2.0898\n",
      "Epoch [17/50], d_loss: 0.5000, g_loss: 2.0899, val_loss: 2.0882\n",
      "Epoch [18/50], d_loss: 0.5000, g_loss: 2.0879, val_loss: 2.0871\n",
      "Epoch [19/50], d_loss: 0.5000, g_loss: 2.0873, val_loss: 2.0843\n",
      "Early stopping\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.0000, g_loss: 4.8027, val_loss: 3.7054\n",
      "Epoch [2/50], d_loss: 0.0002, g_loss: 3.7381, val_loss: 2.6695\n",
      "Epoch [3/50], d_loss: 0.5106, g_loss: 2.3865, val_loss: 2.3965\n",
      "Epoch [4/50], d_loss: 0.5000, g_loss: 2.3723, val_loss: 2.3583\n",
      "Epoch [5/50], d_loss: 0.5000, g_loss: 2.2178, val_loss: 2.2097\n",
      "Epoch [6/50], d_loss: 0.5000, g_loss: 2.1612, val_loss: 2.1601\n",
      "Epoch [7/50], d_loss: 0.5000, g_loss: 2.1528, val_loss: 2.1511\n",
      "Epoch [8/50], d_loss: 0.5000, g_loss: 2.1446, val_loss: 2.1465\n",
      "Epoch [9/50], d_loss: 0.5000, g_loss: 2.1375, val_loss: 2.1378\n",
      "Epoch [10/50], d_loss: 0.5000, g_loss: 2.1183, val_loss: 2.1172\n",
      "Epoch [11/50], d_loss: 0.5000, g_loss: 2.1099, val_loss: 2.1109\n",
      "Epoch [12/50], d_loss: 0.5000, g_loss: 2.1079, val_loss: 2.1047\n",
      "Epoch [13/50], d_loss: 0.5000, g_loss: 2.1016, val_loss: 2.0994\n",
      "Epoch [17/50], d_loss: 0.5000, g_loss: 2.0952, val_loss: 2.0922\n",
      "Epoch [18/50], d_loss: 0.5000, g_loss: 2.0970, val_loss: 2.0914\n",
      "Epoch [19/50], d_loss: 0.5000, g_loss: 2.0899, val_loss: 2.0911\n",
      "Epoch [20/50], d_loss: 0.5000, g_loss: 2.0926, val_loss: 2.0919\n",
      "Early stopping\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.0000, g_loss: 4.8376, val_loss: 3.7623\n",
      "Epoch [2/50], d_loss: 0.5000, g_loss: 2.8652, val_loss: 2.8302\n",
      "Epoch [3/50], d_loss: 0.5000, g_loss: 2.5524, val_loss: 2.5190\n",
      "Epoch [4/50], d_loss: 0.5001, g_loss: 2.2705, val_loss: 2.2568\n",
      "Epoch [5/50], d_loss: 0.5000, g_loss: 2.1832, val_loss: 2.1806\n",
      "Epoch [6/50], d_loss: 0.5000, g_loss: 2.1621, val_loss: 2.1593\n",
      "Epoch [7/50], d_loss: 0.5000, g_loss: 2.1542, val_loss: 2.1506\n",
      "Epoch [8/50], d_loss: 0.5000, g_loss: 2.1485, val_loss: 2.1451\n",
      "Epoch [9/50], d_loss: 0.5000, g_loss: 2.1359, val_loss: 2.1327\n",
      "Epoch [10/50], d_loss: 0.5000, g_loss: 2.1184, val_loss: 2.1162\n",
      "Epoch [11/50], d_loss: 0.5000, g_loss: 2.1105, val_loss: 2.1093\n",
      "Epoch [12/50], d_loss: 0.5000, g_loss: 2.1042, val_loss: 2.1030\n",
      "Epoch [13/50], d_loss: 0.5000, g_loss: 2.0990, val_loss: 2.0981\n",
      "Epoch [14/50], d_loss: 0.5000, g_loss: 2.0965, val_loss: 2.0942\n",
      "Epoch [15/50], d_loss: 0.5000, g_loss: 2.0930, val_loss: 2.0923\n",
      "Epoch [16/50], d_loss: 0.5000, g_loss: 2.0924, val_loss: 2.0920\n",
      "Epoch [17/50], d_loss: 0.5000, g_loss: 2.0918, val_loss: 2.0899\n",
      "Epoch [18/50], d_loss: 0.5000, g_loss: 2.0892, val_loss: 2.0884\n",
      "Epoch [19/50], d_loss: 0.5000, g_loss: 2.0854, val_loss: 2.0887\n",
      "Epoch [20/50], d_loss: 0.5000, g_loss: 2.0834, val_loss: 2.0860\n",
      "Early stopping\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.0000, g_loss: 4.8144, val_loss: 3.7294\n",
      "Epoch [2/50], d_loss: 0.5000, g_loss: 2.9732, val_loss: 2.9529\n",
      "Epoch [3/50], d_loss: 0.5002, g_loss: 2.7584, val_loss: 2.7284\n",
      "Epoch [4/50], d_loss: 0.5000, g_loss: 2.4022, val_loss: 2.3805\n",
      "Epoch [5/50], d_loss: 0.5000, g_loss: 2.2194, val_loss: 2.2150\n",
      "Epoch [6/50], d_loss: 0.5000, g_loss: 2.1698, val_loss: 2.1687\n",
      "Epoch [7/50], d_loss: 0.5000, g_loss: 2.1551, val_loss: 2.1567\n",
      "Epoch [8/50], d_loss: 0.5000, g_loss: 2.1481, val_loss: 2.1515\n",
      "Epoch [9/50], d_loss: 0.5000, g_loss: 2.1489, val_loss: 2.1492\n",
      "Epoch [10/50], d_loss: 0.5000, g_loss: 2.1419, val_loss: 2.1448\n",
      "Epoch [11/50], d_loss: 0.5000, g_loss: 2.1327, val_loss: 2.1317\n",
      "Epoch [12/50], d_loss: 0.5000, g_loss: 2.1190, val_loss: 2.1175\n",
      "Epoch [13/50], d_loss: 0.5000, g_loss: 2.1143, val_loss: 2.1111\n",
      "Epoch [14/50], d_loss: 0.5000, g_loss: 2.1030, val_loss: 2.1061\n",
      "Epoch [15/50], d_loss: 0.5000, g_loss: 2.1006, val_loss: 2.1014\n",
      "Epoch [16/50], d_loss: 0.5000, g_loss: 2.0982, val_loss: 2.0988\n",
      "Epoch [17/50], d_loss: 0.5000, g_loss: 2.0963, val_loss: 2.0966\n",
      "Epoch [18/50], d_loss: 0.5000, g_loss: 2.0978, val_loss: 2.0958\n",
      "Epoch [19/50], d_loss: 0.5000, g_loss: 2.0910, val_loss: 2.0940\n",
      "Epoch [20/50], d_loss: 0.5000, g_loss: 2.0937, val_loss: 2.0947\n",
      "Epoch [21/50], d_loss: 0.5000, g_loss: 2.0923, val_loss: 2.0924\n",
      "Epoch [22/50], d_loss: 0.5000, g_loss: 2.0892, val_loss: 2.0917\n",
      "Epoch [23/50], d_loss: 0.5000, g_loss: 2.0923, val_loss: 2.0905\n",
      "Early stopping\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch [1/50], d_loss: 0.0000, g_loss: 4.7533, val_loss: 3.6372\n",
      "Epoch [2/50], d_loss: 0.0005, g_loss: 3.6792, val_loss: 2.6194\n",
      "Epoch [3/50], d_loss: 0.5000, g_loss: 2.3097, val_loss: 2.2925\n",
      "Epoch [4/50], d_loss: 0.5000, g_loss: 2.1955, val_loss: 2.1919\n",
      "Epoch [5/50], d_loss: 0.5000, g_loss: 2.1593, val_loss: 2.1603\n",
      "Epoch [6/50], d_loss: 0.5000, g_loss: 2.1457, val_loss: 2.1467\n",
      "Epoch [7/50], d_loss: 0.5000, g_loss: 2.1266, val_loss: 2.1238\n",
      "Epoch [8/50], d_loss: 0.5000, g_loss: 2.1181, val_loss: 2.1133\n",
      "Epoch [9/50], d_loss: 0.5000, g_loss: 2.1171, val_loss: 2.1081\n",
      "Epoch [10/50], d_loss: 0.5000, g_loss: 2.1216, val_loss: 2.1034\n",
      "Epoch [11/50], d_loss: 0.5000, g_loss: 2.1011, val_loss: 2.0992\n",
      "Epoch [12/50], d_loss: 0.5000, g_loss: 2.0947, val_loss: 2.0975\n",
      "Epoch [13/50], d_loss: 0.5000, g_loss: 2.0961, val_loss: 2.0955\n",
      "Epoch [14/50], d_loss: 0.5000, g_loss: 2.1129, val_loss: 2.0951\n",
      "Epoch [15/50], d_loss: 0.5000, g_loss: 2.0924, val_loss: 2.0950\n",
      "Epoch [16/50], d_loss: 0.5000, g_loss: 2.0933, val_loss: 2.0934\n",
      "Early stopping\n",
      "CPU times: user 8min 58s, sys: 6min 55s, total: 15min 53s\n",
      "Wall time: 1h 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    trainloader = DataLoader(dataset, batch_size=8192, sampler=train_subsampler,num_workers=8)\n",
    "    testloader = DataLoader(dataset, batch_size=8192, sampler=test_subsampler,num_workers=8)\n",
    "\n",
    "    generator, discriminator = create_models()\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        for data in trainloader:\n",
    "            A_batch, B_batch = data\n",
    "            A_batch, B_batch = A_batch.to(device), B_batch.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            real_output = discriminator(B_batch)\n",
    "            fake_B = generator(A_batch)\n",
    "            fake_output = discriminator(fake_B.detach())\n",
    "            d_loss_real = criterion(real_output, torch.ones_like(real_output))\n",
    "            d_loss_fake = criterion(fake_output, torch.zeros_like(fake_output))\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_output = discriminator(fake_B)\n",
    "            g_loss = criterion(fake_output, torch.ones_like(fake_output)) + criterion(fake_B, B_batch)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "        # validate\n",
    "        generator.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                A_batch, B_batch = data\n",
    "                A_batch, B_batch = A_batch.to(device), B_batch.to(device)\n",
    "                fake_B = generator(A_batch)\n",
    "                val_loss += criterion(fake_B, B_batch).item()\n",
    "        \n",
    "        val_loss /= len(testloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, val_loss: {val_loss:.4f}')\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d479ea7-74be-45a1-aeb8-c2cbbf298f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=500, out_features=500, bias=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=23418, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9c3de2-9c18-4ed6-b483-e9b2fb1c1cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60343105, 0.3458233 , 0.34303367, ..., 1.4880004 , 1.259369  ,\n",
       "        2.474244  ],\n",
       "       [0.6014136 , 0.34502655, 0.3446757 , ..., 1.4828991 , 1.2593346 ,\n",
       "        2.4766738 ],\n",
       "       [0.59464055, 0.34384373, 0.34512666, ..., 1.4688619 , 1.2545477 ,\n",
       "        2.4668083 ],\n",
       "       ...,\n",
       "       [0.4066004 , 0.2936568 , 0.30199626, ..., 0.94134074, 0.9706296 ,\n",
       "        1.7565163 ],\n",
       "       [0.4168693 , 0.29230085, 0.30114892, ..., 0.97669625, 0.9810226 ,\n",
       "        1.7901096 ],\n",
       "       [0.39712453, 0.29427043, 0.30096447, ..., 0.90688264, 0.96370304,\n",
       "        1.729365  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_B_from_A(new_A):\n",
    "    new_A_tensor = torch.tensor(new_A, dtype=torch.float32)\n",
    "    dataset = TensorDataset(new_A_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "    generator.eval()\n",
    "    generated_B = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            A_batch = data[0].cuda()\n",
    "            fake_B = generator(A_batch)\n",
    "            generated_B.append(fake_B.cpu().numpy())\n",
    "    \n",
    "    generated_B = np.concatenate(generated_B, axis=0)\n",
    "    return generated_B\n",
    "\n",
    "generated_B = generate_B_from_A(test_multi_X)\n",
    "generated_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f121ac-4020-49e6-98e8-2157c130b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55935, 23418)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf1a1d-0905-4dfd-9e34-177311424dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "######data  collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d71d55-2373-4775-96a6-f2d5e4ea8265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = '../dataset/'\n",
    "metadata = pd.read_csv(input_path+'metadata.csv')[['cell_id','technology']]\n",
    "evaluation_ids = pd.read_csv(input_path+'evaluation_ids.csv')\n",
    "evaluation_ids = evaluation_ids.merge(metadata, on=['cell_id'], how='left')\n",
    "\n",
    "# multi\n",
    "train_multi_targets = pd.read_hdf(input_path+'train_multi_targets.h5')\n",
    "multi_targets = train_multi_targets.columns.values.tolist()\n",
    "\n",
    "del train_multi_targets\n",
    "gc.collect()\n",
    "\n",
    "test_preds_multi = pd.DataFrame(generated_B, columns=multi_targets)\n",
    "\n",
    "test_multi_inputs_id = pd.read_feather(feature_path+'test_multi_inputs_id.feather')\n",
    "test_preds_multi['cell_id'] = test_multi_inputs_id['cell_id']\n",
    "test_preds_multi = test_preds_multi[test_preds_multi['cell_id'].isin(evaluation_ids['cell_id'])]\n",
    "test_preds_multi = pd.melt(test_preds_multi,id_vars='cell_id')\n",
    "test_preds_multi.columns = ['cell_id','gene_id','target']\n",
    "\n",
    "del test_multi_inputs_id\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037d8448-8e3f-4401-a9fd-f711220ecdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2150f55becb</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.599453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b7edf8a4da</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.599510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1b26cb1057b</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.586568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>917168fa6f83</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.593099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b29feeca86d</td>\n",
       "      <td>CD86</td>\n",
       "      <td>0.589955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812815</th>\n",
       "      <td>a9b4d99f1f50</td>\n",
       "      <td>CD224</td>\n",
       "      <td>2.738467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812816</th>\n",
       "      <td>0e2c1d0782af</td>\n",
       "      <td>CD224</td>\n",
       "      <td>2.715506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812817</th>\n",
       "      <td>a3cbc5aa0ec3</td>\n",
       "      <td>CD224</td>\n",
       "      <td>5.346298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812818</th>\n",
       "      <td>75b350243add</td>\n",
       "      <td>CD224</td>\n",
       "      <td>3.651095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812819</th>\n",
       "      <td>ad5a949989b2</td>\n",
       "      <td>CD224</td>\n",
       "      <td>4.561980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812820 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cell_id gene_id    target\n",
       "0        c2150f55becb    CD86  0.599453\n",
       "1        65b7edf8a4da    CD86  0.599510\n",
       "2        c1b26cb1057b    CD86  0.586568\n",
       "3        917168fa6f83    CD86  0.593099\n",
       "4        2b29feeca86d    CD86  0.589955\n",
       "...               ...     ...       ...\n",
       "6812815  a9b4d99f1f50   CD224  2.738467\n",
       "6812816  0e2c1d0782af   CD224  2.715506\n",
       "6812817  a3cbc5aa0ec3   CD224  5.346298\n",
       "6812818  75b350243add   CD224  3.651095\n",
       "6812819  ad5a949989b2   CD224  4.561980\n",
       "\n",
       "[6812820 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_cite = pd.read_csv('../dataset/pred_cite.csv',index_col=0)\n",
    "test_preds_cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7168cf9a-4565-42e6-b703-741c4b7cfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge final results\n",
    "test_preds = pd.concat([test_preds_cite,test_preds_multi])\n",
    "evaluation_ids = evaluation_ids.merge(test_preds, on=['cell_id','gene_id'], how='left')\n",
    "evaluation_ids[['row_id','target']].to_csv('../dataset/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
